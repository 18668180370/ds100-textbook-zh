# 五、探索性数据分析

> 探索性数据分析是一种态度，一种灵活的状态，一种寻找那些我们认为不存在和存在的东西的心愿。
> 
> [John Tukey](https://en.wikipedia.org/wiki/John_Tukey)

在探索性数据分析（EDA），也就是数据科学生命周期的第三步中，我们总结，展示和转换数据，以便更深入地理解它。 特别是，通过 EDA，我们发现数据中的潜在问题，并发现可用于进一步分析的趋势。

我们试图了解我们数据的以下属性：

结构：我们数据文件的格式。
粒度：每行和每列的精细程度。
范围：我们的数据有多么完整或不完整。
时间性：数据是不是当时的情况。
忠诚度：数据捕捉“现实”有多好。

尽管我们分别介绍了数据清理和 EDA 来有助于组织本书，但在实践中，你经常会在两者之间切换。 例如，列的可视化可能会向你展示，应使用数据清理技术进行处理的格式错误的值。 考虑到这一点，我们回顾伯克利警察局的数据集来进行探索。

## 结构和连接

### 结构

数据集的结构指的是数据文件的“形状”。 基本上，这指的是输入数据的格式。例如，我们看到呼叫数据集是 CSV（逗号分隔值）文件：

```
!head data/Berkeley_PD_-_Calls_for_Service.csv

CASENO,OFFENSE,EVENTDT,EVENTTM,CVLEGEND,CVDOW,InDbDate,Block_Location,BLKADDR,City,State
17091420,BURGLARY AUTO,07/23/2017 12:00:00 AM,06:00,BURGLARY - VEHICLE,0,08/29/2017 08:28:05 AM,"2500 LE CONTE AVE
Berkeley, CA
(37.876965, -122.260544)",2500 LE CONTE AVE,Berkeley,CA
17020462,THEFT FROM PERSON,04/13/2017 12:00:00 AM,08:45,LARCENY,4,08/29/2017 08:28:00 AM,"2200 SHATTUCK AVE
Berkeley, CA
(37.869363, -122.268028)",2200 SHATTUCK AVE,Berkeley,CA
17050275,BURGLARY AUTO,08/24/2017 12:00:00 AM,18:30,BURGLARY - VEHICLE,4,08/29/2017 08:28:06 AM,"200 UNIVERSITY AVE
Berkeley, CA
(37.865491, -122.310065)",200 UNIVERSITY AVE,Berkeley,CA
```

另一方面，截停数据集是 JSON（JavaScript 对象表示法）文件。

```
# Show first and last 5 lines of file
!head -n 5 data/stops.json
!echo '...'
!tail -n 5 data/stops.json

{
  "meta" : {
    "view" : {
      "id" : "6e9j-pj9p",
      "name" : "Berkeley PD - Stop Data",
...
, [ 31079, "C2B606ED-7872-4B0B-BC9B-4EF45149F34B", 31079, 1496269085, "932858", 1496269085, "932858", null, "2017-00024245", "2017-04-30T22:59:26", " UNIVERSITY AVE/6TH ST", "T", "BM2TWN; ", null, null ]
, [ 31080, "8FADF18D-7FE9-441D-8709-7BFEABDACA7A", 31080, 1496269085, "932858", 1496269085, "932858", null, "2017-00024250", "2017-04-30T23:19:27", " UNIVERSITY AVE /  WEST ST", "T", "HM4TCS; ", "37.8698757000001", "-122.286550846" ]
, [ 31081, "F60BD2A4-8C47-4BE7-B1C6-4934BE9DF838", 31081, 1496269085, "932858", 1496269085, "932858", null, "2017-00024254", "2017-04-30T23:38:34", " CHANNING WAY /  BOWDITCH ST", "1194", "AR; ", "37.867207539", "-122.256529377" ]
 ]
}
```

当然，还有很多其他类型的数据格式。 以下是最常见格式的列表：

+   逗号分隔值（CSV）和制表符分隔值（TSV）。 这些文件包含由逗号（CSV）或制表符（`\t`，TSV）分隔的表格数据。 这些文件通常很容易处理，因为数据的输入格式与`DataFrame`类似。

+   JavaScript 对象表示法（JSON）。 这些文件包含嵌套字典格式的数据。 通常我们必须将整个文件读为 Python 字典，然后弄清楚如何从字典中为`DataFrame`提取字段。

+   可扩展标记语言（XML）或超文本标记语言（HTML）。 这些文件也包含嵌套格式的数据，例如：

    ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    <note>
        <to>Tove</to>
        <from>Jani</from>
        <heading>Reminder</heading>
        <body>Don't forget me this weekend!</body>
    </note>
    ```
    
    在后面的章节中，我们将使用 XPath 从这些类型的文件中提取数据。

+   日志数据。许多应用在运行时会以非结构化文本格式输出一些数据，例如：

    ```
    2005-03-23 23:47:11,663 - sa - INFO - creating an instance of aux_module.Aux
    2005-03-23 23:47:11,665 - sa.aux.Aux - INFO - creating an instance of Aux
    2005-03-23 23:47:11,665 - sa - INFO - created an instance of aux_module.Aux
    2005-03-23 23:47:11,668 - sa - INFO - calling aux_module.Aux.do_something
    2005-03-23 23:47:11,668 - sa.aux.Aux - INFO - doing something
    ```
    
    在后面的章节中，我们将使用正则表达式从这些类型的文件中提取数据。

### 连接（Join）

数据通常会分成多个表格。 例如，一张表可能描述一些人的个人信息，而另一张表可能包含他们的电子邮件：

```py
personal information while another will contain their emails:

people = pd.DataFrame(
    [["Joey",      "blue",    42,  "M"],
     ["Weiwei",    "blue",    50,  "F"],
     ["Joey",      "green",    8,  "M"],
     ["Karina",    "green",    7,  "F"],
     ["Nhi",       "blue",     3,  "F"],
     ["Sam",       "pink",   -42,  "M"]], 
    columns = ["Name", "Color", "Number", "Sex"])

people
```

|  | Name | Color | Number | Sex |
| --- | --- | --- | --- | --- |
| 0 | Joey | blue | 42 | M |
| 1 | Weiwei | blue | 50 | F |
| 2 | Joey | green | 8 | M |
| 3 | Karina | green | 7 | F |
| 4 | Fernando | pink | -9 | M |
| 5 | Nhi | blue | 3 | F |
| 6 | Sam | pink | -42 | M |

```py
email = pd.DataFrame(
    [["Deb",  "deborah_nolan@berkeley.edu"],
     ["Sam",  "samlau95@berkeley.edu"],
     ["John", "doe@nope.com"],
     ["Joey", "jegonzal@cs.berkeley.edu"],
     ["Weiwei", "weiwzhang@berkeley.edu"],
     ["Weiwei", "weiwzhang+123@berkeley.edu"],
     ["Karina", "kgoot@berkeley.edu"]], 
    columns = ["User Name", "Email"])

email
```

| | User Name | Email |
| --- | --- | --- |
| 0 | Deb | deborah_nolan@berkeley.edu |
| 1 | Sam | samlau95@berkeley.edu |
| 2 | John | doe@nope.com |
| 3 | Joey | jegonzal@cs.berkeley.edu |
| 4 | Weiwei | weiwzhang@berkeley.edu |
| 5 | Weiwei | weiwzhang+123@berkeley.edu |
| 6 | Karina | kgoot@berkeley.edu |

为了使每个人匹配他或她的电子邮件，我们可以在包含用户名的列上连接两个表。 然后，我们必须决定，如何处理出现在一张表上而没有在另一张表上的人。 例如，`Fernando`出现在`people`表中，但不出现在`email`表中。 我们有几种类型的连接，用于每个匹配缺失值的策略。 最常见的连接之一是内连接，其中任何不匹配的行都不放入最终结果中：

```py
# Fernando, Nhi, Deb, and John don't appear
people.merge(email, how='inner', left_on='Name', right_on='User Name')
```


| | Name | Color | Number | Sex | User Name | Email |
| --- | --- | --- | --- | --- | --- | --- |
| 0 | Joey | blue | 42 | M | Joey | jegonzal@cs.berkeley.edu |
| 1 | Joey | green | 8 | M | Joey | jegonzal@cs.berkeley.edu |
| 2 | Weiwei | blue | 50 | F | Weiwei | weiwzhang@berkeley.edu |
| 3 | Weiwei | blue | 50 | F | Weiwei | weiwzhang+123@berkeley.edu |
| 4 | Karina | green | 7 | F | Karina | kgoot@berkeley.edu |
| 5 | Sam | pink | -42 | M | Sam | samlau95@berkeley.edu |

这是我们经常使用的四个基本连接：内连接，全连接（有时称为“外连接”），左连接和右连接。 以下是个图表，展示了这些类型的连接之间的区别。

![](img/5-1.png)

运行下面的代码，并使用生成的下拉菜单，来展示`people`和`email `表格的四种不同的连接的结果。 注意对于外，左和右连接，哪些行包含了`NaN`值。

```py
# HIDDEN
def join_demo(join_type):
    display(HTML('people and email tables:'))
    display_two(people, email)
    display(HTML('<br>'))
    display(HTML('Joined table:'))
    display(people.merge(email, how=join_type,
                         left_on='Name', right_on='User Name'))
    
interact(join_demo, join_type=['inner', 'outer', 'left', 'right']);
```

### 结构检查清单

查看数据集的结构之后，你应该回答以下问题。我们将根据呼叫和截停数据集回答它们。

数据是标准格式还是编码过的？

标准格式包括：

表格数据：CSV，TSV，Excel，SQL
嵌套数据：JSON，XML

呼叫数据集采用 CSV 格式，而截停数据集采用 JSON 格式。

数据是组织为记录形式（例如行）的吗？如果不是，我们可以通过解析数据来定义记录吗？

呼叫数据集按行出现；我们从截停数据集中提取记录。

数据是否嵌套？如果是这样，我们是否可以适当地提取非嵌套的数据？

呼叫数据集不是嵌套的；我们不必过于费力从截停数据集中获取非嵌套的数据。

数据是否引用了其他数据？如果是这样，我们可以连接数据吗？

呼叫数据集引用了星期表。连接这两张表让我们知道数据集中每个事件的星期。截取数据集没有明显的引用。

每个记录中的字段（例如，列）是什么？每列的类型是什么？

呼叫和截停数据集的字段，在每个数据集的“数据清理”一节中介绍。
